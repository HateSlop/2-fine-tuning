{"cells":[{"cell_type":"code","source":["!pip install transformers datasets peft accelerate torch sklearn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyuldwwdhf4N","executionInfo":{"status":"ok","timestamp":1747297949012,"user_tz":-540,"elapsed":2295,"user":{"displayName":"정한결","userId":"07913795484686100489"}},"outputId":"5f18ddaf-5a87-410e-d04a-ee322da621ca"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting sklearn\n","  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}]},{"cell_type":"code","source":["!pip install -U datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIxNjOqeGFrM","executionInfo":{"status":"ok","timestamp":1747297953559,"user_tz":-540,"elapsed":4544,"user":{"displayName":"정한결","userId":"07913795484686100489"}},"outputId":"87ed577c-655f-4eb9-bd74-8c53ba24c2c7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import os\n","device = 0 if torch.cuda.is_available() else -1"],"metadata":{"id":"D8IJ4mlSiL_A","executionInfo":{"status":"ok","timestamp":1747297957535,"user_tz":-540,"elapsed":3972,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from random import shuffle\n","from datasets import load_dataset\n","# whole_data = load_dataset(\"dev7halo/bluehouse-national-petition\")\n","klue_train = load_dataset('klue', 'ynat', split='train')\n","klue_evaluate = load_dataset('klue', 'ynat', split='validation')\n","klue_train = klue_train.remove_columns(['guid', 'url', 'date'])\n","klue_evaluate = klue_evaluate.remove_columns(['guid', 'url', 'date'])\n","# whole_data = whole_data.remove_columns(['number', '제목', '답변상태', '참여인원', '청원시작','청원마감','답변원고'])\n","# sample_data = whole_data['train'].train_test_split(test_size=0.05, shuffle=True, seed=37)['test']\n","# sample_data = sample_data.train_test_split(test_size=20000, shuffle=True, seed=37)\n","# train_data = sample_data['test']\n","# valid_test = sample_data['train'].train_test_split(test_size = 1000, shuffle=True, seed=37)\n","# valid_data = valid_test['train']\n","# test_data = valid_test['test']\n","train_data = klue_train.train_test_split(test_size=10000, shuffle=True, seed=37)['test']\n","test_and_valid_data = klue_evaluate.train_test_split(test_size=1000, shuffle=True, seed=37)\n","test_data = test_and_valid_data['test']\n","valid_data = test_and_valid_data['train'].train_test_split(test_size=1000, shuffle=True, seed=37)['test']"],"metadata":{"id":"wvegSwDgihrk","executionInfo":{"status":"ok","timestamp":1747297965986,"user_tz":-540,"elapsed":8456,"user":{"displayName":"정한결","userId":"07913795484686100489"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2518983-30c2-4095-a73d-bb67ed45c933"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["model_id='klue/roberta-base'"],"metadata":{"id":"39aH2H0cLa-X","executionInfo":{"status":"ok","timestamp":1747297965990,"user_tz":-540,"elapsed":7,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":25,"metadata":{"vscode":{"languageId":"plaintext"},"id":"qXsI2zYedJK5","executionInfo":{"status":"ok","timestamp":1747298413438,"user_tz":-540,"elapsed":26,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from peft import LoraConfig, get_peft_model\n","\n","def load_model_and_tokenizer(model_id, peft=None):\n","    tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","    if peft is None:\n","        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=\"auto\", device_map={\"\":0})\n","\n","    elif peft == 'lora':\n","        # model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=\"auto\", device_map={\"\":0})\n","        model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_data.features['label'].names))\n","        lora_config = LoraConfig(\n","                    r=8,\n","                    lora_alpha=32,\n","                    target_modules=[\"query\", \"value\"],\n","                    lora_dropout=0.05,\n","                    bias=\"none\",\n","                    task_type=\"SEQ_CLS\"\n","                )\n","\n","        model = get_peft_model(model, lora_config)\n","        model.print_trainable_parameters()\n","\n","    # print_gpu_utilization()\n","    return model, tokenizer"]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_id)\n","def tokenizing_function(samples):\n","  return tokenizer(samples['title'], padding='max_length', truncation=True)\n","\n","train_data = train_data.map(tokenizing_function, batched=True)\n","valid_data = valid_data.map(tokenizing_function, batched=True)\n","test_data = test_data.map(tokenizing_function, batched=True)"],"metadata":{"id":"Dt3sFThHnf0f","executionInfo":{"status":"ok","timestamp":1747297986688,"user_tz":-540,"elapsed":321,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","import numpy as np\n","from torch import cuda\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    acc = accuracy_score(labels, predictions)\n","    return {\"accuracy\": acc}"],"metadata":{"id":"DYe0TB4pXqYH","executionInfo":{"status":"ok","timestamp":1747297986714,"user_tz":-540,"elapsed":11,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoModelForMaskedLM\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=1,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    eval_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    push_to_hub=False,\n",")"],"metadata":{"id":"HyvZsraU2Oi4","executionInfo":{"status":"ok","timestamp":1747297988423,"user_tz":-540,"elapsed":1706,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["torch.cuda.reset_peak_memory_stats()\n","model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_data.features['label'].names))\n","\n","#--without lora--#\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=valid_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","train_out = trainer.train()\n","eval_data = trainer.evaluate(test_data)\n","eval_acc = eval_data[\"eval_accuracy\"]\n","train_time = train_out.metrics[\"train_runtime\"]\n","max_memory = torch,cuda.max_memory_allocated() / (1024**3)\n","model.save_pretrained(\"tmp_model\")\n","model_size = sum(os.path.getsize(os.path.join(\"tmp_model\", f)) for f in os.listdir(\"tmp_model\")) / 1024**2\n","# model_size = sum(p.numel() for p in model.parameters()) * 4 / (1024**2)"],"metadata":{"id":"EyQdg7Gzo0wD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747301706592,"user_tz":-540,"elapsed":2164,"user":{"displayName":"정한결","userId":"07913795484686100489"}},"outputId":"acba05df-c0a2-4b0e-e9e6-dbe3a0fe5864"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","<ipython-input-34-3845272dd6cc>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]}]},{"cell_type":"code","source":["#--using lora--#\n","torch.cuda.reset_peak_memory_stats()\n","model_lora, tokenizer_lora = load_model_and_tokenizer(model_id, 'lora')\n","trainer_lora = Trainer(\n","    model=model_lora,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=valid_data,\n","    tokenizer=tokenizer_lora,\n","    compute_metrics=compute_metrics\n",")\n","train_out_lora = trainer_lora.train()\n","eval_data_lora = trainer_lora.evaluate(test_data)\n","eval_acc_lora = eval_data_lora[\"eval_accuracy\"]\n","train_time_lora = train_out_lora.metrics[\"train_runtime\"]\n","max_memory_lora = torch,cuda.max_memory_allocated() / (1024**3)\n","\n","model_lora.save_pretrained(\"tmp_model\")\n","model_size_lora = sum(os.path.getsize(os.path.join(\"tmp_model\", f)) for f in os.listdir(\"tmp_model\")) / 1024**2\n","# model_size_lora = sum(p.numel() for p in model_lora.parameters()) * 4 / (1024**2)\n"],"metadata":{"id":"J4itg-2oOBYP","executionInfo":{"status":"ok","timestamp":1747302506357,"user_tz":-540,"elapsed":250,"user":{"displayName":"정한결","userId":"07913795484686100489"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["print(f\"{eval_acc} | {eval_acc_lora}\")\n","print(f\"{train_time} | {train_time_lora}\")\n","print(f\"{max_memory[1]}GB | {max_memory_lora[1]}GB\")\n","print(f\"{model_size}MB | {model_size_lora}MB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bTD7C44acJo","executionInfo":{"status":"ok","timestamp":1747302510059,"user_tz":-540,"elapsed":17,"user":{"displayName":"정한결","userId":"07913795484686100489"}},"outputId":"3b323616-479c-486b-f1ca-f1d8397f34a5"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["0.868 | 0.768\n","947.5343 | 707.2173\n","2.1715545654296875GB | 2.836458683013916GB\n","422.01915168762207MB | 425.4302291870117MB\n"]}]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}