{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75856,
     "status": "ok",
     "timestamp": 1747011527628,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "Qy7Z4b4PGJod",
    "outputId": "1eb5b66d-2b66-43e4-dd4e-8da17969badd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/10.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/10.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m8.1/10.2 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.50.0 datasets==3.5.0 huggingface_hub==0.29.0 peft accelerate torch scikit-learn -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2583,
     "status": "ok",
     "timestamp": 1747011535000,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "Nlif9zka3Y0N",
    "outputId": "79d491b9-9ddd-4f8e-8a23-cf3ffddfb85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능 (CUDA)\n",
      "→ 사용 중인 GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 사용 가능 (CUDA)\")\n",
    "    print(f\"→ 사용 중인 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU 사용 불가 (현재 CPU 모드)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503,
     "referenced_widgets": [
      "e0f5539ac0814ce28928de881e18f020",
      "db68008b184f493d866030e9a23e500c",
      "407e076c6bcf4a5fb176e49b4ea029d5",
      "77d68c908e61428f818cd1af636dd47a",
      "ffb2a50d007b496883256e853bd02b70",
      "359fc37517b14d6db903e258d2bd4cd5",
      "31af350a2c5840069ff0516b566d96e1",
      "73c38f2c659d4f0b8598dfa276b231c0",
      "e8f81e3b43034b9da18a908266d74a47",
      "65a8d403d62048e68700de58c7bd9dba",
      "8346cf1d16f243cb8a14f7320a04ffa0",
      "85d9daed966746dbbc753b5270d8c4ed",
      "f9c1a3b1627e4e6b883dd5f0e39c5238",
      "519e85c667e2496aa7390fc2142cde1b",
      "bd0a1f4a1ff243fba690d5c9f5cb2250",
      "88128563420447c58a75e91b30c7c27a",
      "96302d0dc74a4fd882b840b532b8848b",
      "62afc6bcbe414df48e3cee3092f234d1",
      "d063d5f02ca54857881abc1f2e29eb1b",
      "7f6193db9de749729191a94bd7d44d91",
      "5070f68c7cd74f0ca97d08ebfc8b313a",
      "67d12695281646fb9e21a5ea8e86854e",
      "9f41947911c94568a501e1769ddf2045",
      "d68da459983141eaa760d3cba7a45016",
      "2a800485238c49d09b04fae502d47953",
      "18a25731466043f39f45c15884c2c8a6",
      "144f82b2c5664d2894d2a16955945c40",
      "5e21b50eaa764f339c080d5c3ac9afee",
      "d9b384f214fd4253801f475a8c43fdc1",
      "a1a7e093b377495a94c354078708f6e5",
      "ab885899d7844454a9fb6c2cf62a5a84",
      "7d0411ef89d64c7f86fcf233b1282c90",
      "9123ad2ce7b341de8474c35ca9d40b8f",
      "3c9122c6fa504f6aa8ba7bbfc8c91534",
      "363c686fb7fe47a88ea88bc8c432b2c1",
      "624666bd4a4b486fb32777bc98f61442",
      "87df6fa75bc940abb505a0cc145a1031",
      "f7be1a8bb0824788be125c6bc5bcfc4b",
      "8641f8b59174436bbe09e8f98399a8df",
      "dc2336ded8c248289b8c85456405a9b7",
      "474aca455fd241c3864a55db2de9033a",
      "5e3316ef17bb49a2a0798290fdb5159e",
      "8a3a4af68e9b4f35bf3def6ac066c487",
      "efadab85a77f400a8840c3e28b64cc29",
      "8a96ac89164f4060a96b7c5e1aaebc28",
      "b6de516d7dc6427ebccb539439f0ae42",
      "6bcf85f19f524c36b66bd48b1e2414b6",
      "8eb605fd78cf4e7ebb649714c5c34a1b",
      "2201120d703e4981b38a8d3d0d8ff401",
      "f4ec701fba5e487db62b4272f5ffded0",
      "0cd8ba3b37744c67af76b068a7cbb482",
      "400bcd4be2884a4b8895aa6eeba7952e",
      "954e95f00bf34be6b0d8aa6fa10ad374",
      "732758c145d1417f828aeb16fda81988",
      "72f6c9d2a5f5467598756c56fbd5a7d0"
     ]
    },
    "executionInfo": {
     "elapsed": 17255,
     "status": "ok",
     "timestamp": 1747011554317,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "TOzvLM-AGQiy",
    "outputId": "80205d18-c7d7-41f6-f1a0-fda37b769559"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f5539ac0814ce28928de881e18f020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d9daed966746dbbc753b5270d8c4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/4.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f41947911c94568a501e1769ddf2045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/847k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9122c6fa504f6aa8ba7bbfc8c91534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a96ac89164f4060a96b7c5e1aaebc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['guid', 'title', 'label', 'url', 'date'],\n",
       "     num_rows: 45678\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['guid', 'title', 'label', 'url', 'date'],\n",
       "     num_rows: 9107\n",
       " }))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "klue_tc_train = load_dataset('klue', 'ynat', split = 'train')\n",
    "klue_tc_eval = load_dataset('klue', 'ynat', split = 'validation')\n",
    "klue_tc_train, klue_tc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747011564021,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "MDp6d8bWHHFC",
    "outputId": "64324367-9f10-4939-ad29-f1c2fa012883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['title', 'label'],\n",
       "     num_rows: 45678\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'label'],\n",
       "     num_rows: 9107\n",
       " }))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train = klue_tc_train.remove_columns(['guid', 'url', 'date'])\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(['guid', 'url', 'date'])\n",
    "klue_tc_train, klue_tc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "cd1dd961850c4e8599951cc15cfcad50",
      "c26ec1fcca3c4a0d807148ad0fb7b9d3",
      "28b2fd13d7dd4ffcbe6c27dea46ad079",
      "c189c18f43d04c5d8d62340d4efb3a6a",
      "7e06c468f93546c782148ddf0c43e0dd",
      "f94bf992cb83480ab762e457f56ffdd3",
      "ca9ef6b97fa54a32b6d1230f4605cb33",
      "ccb8ecd41865484dbae635a4ff05280a",
      "07af82fa33a541b5b2e2ea9be58825eb",
      "50d30962099a48c681210f51581f94bc",
      "b99c94d1aecb41fb9296800139f43797"
     ]
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1747011566556,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "tT9MkAcXHMiz",
    "outputId": "6e6d5b7c-d1e3-4b33-c80f-8433a20dcb2e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1dd961850c4e8599951cc15cfcad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영', 'label': 3, 'label_str': '생활문화'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label']\n",
    "# ClassLabel(names=['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'], id=None)\n",
    "\n",
    "klue_tc_train.features['label'].int2str(1)\n",
    "# '경제'\n",
    "\n",
    "klue_tc_label = klue_tc_train.features['label']\n",
    "\n",
    "def make_str_label(batch):\n",
    "  batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "  return batch\n",
    "\n",
    "klue_tc_train = klue_tc_train.map(make_str_label, batched=True, batch_size=1000)\n",
    "\n",
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1747011569575,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "-EfRpoP_HNNL",
    "outputId": "f755e619-a8f2-4d1d-82a1-ce1bac393fc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['title', 'label', 'label_str'],\n",
       "     num_rows: 36542\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'label', 'label_str'],\n",
       "     num_rows: 9136\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'label'],\n",
       "     num_rows: 9107\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = klue_tc_train.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "train_dataset = split['train']\n",
    "valid_dataset = split['test']\n",
    "test_dataset = klue_tc_eval\n",
    "train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350,
     "referenced_widgets": [
      "c5be56778384416684dd4c0b3338bd98",
      "3370bd9673234d30baf9645fd725878c",
      "37ceea5030eb4836af0cd7d830de8578",
      "3f83635c920f4b0b8e2260581697d820",
      "64f6450530ab45d3ad49ce49e221bbe3",
      "a293c77ef0444357b57ebaddec469637",
      "9605bd83c95f45a5b0a7c5b241dff5a4",
      "36032b40c4d54422bb8dcffd07abbe14",
      "8e2b8204a8d249a69d4729573b7ce3f6",
      "5b17c91ed7ae4ad185487b0f6d1f164c",
      "fecb1443a5d046fba9ca70b0ea202007",
      "b26684dfd40e446bbc60be9f6fb9da3b",
      "c6fa3648c32a44bbbb9cfa63b3e506d6",
      "01beea1c12ad4d0598698701ffe05131",
      "37e1024a17a04e7fbc9297f3b4e4c7dc",
      "3dcba06e9dd046088d0e85e13577e331",
      "3aaef0e4854a4bfcad45e27dca4779cd",
      "75e86acffe8e42689ffb3c87e98bf574",
      "85785123517649948159f256a2de766b",
      "785a88cf18f7413a9c81517f7784f70d",
      "f5d7523c4954406fb12f50b9c6bc2517",
      "93d673fd363241a4b8f9a5697f3a46ca",
      "f71f867a5fcf42d19ac3584a95ae3805",
      "baa05ddb9b88460da7a77be0a896cee6",
      "956cc88c55f843b58187f2b22287c4d3",
      "37912308c6f748eabb6aceb3d4753d69",
      "ec67353d9dae47818a187409d42d87d4",
      "66af9df7650247ecac8029ee777fd141",
      "cf39d2745cbe417bbcc08b310a7ebe0f",
      "c5ae59278aff4ba480b1b5e4ff54b100",
      "32fd41b72ed3410788af1d72090a691d",
      "2e49b8aef3d04859a3f20aaff952630c",
      "caf654ef3b7d4eb685eb5fdd97b573b3",
      "6f97a1b667494a2a9c7d6a84ff9ca835",
      "30b94ac3c22c407ea3e8558dec02222e",
      "636cdb3b95ef458db7b11c71f02391a3",
      "ee19c73146f64c978c33a1da79563aef",
      "2b5fe97100d4411e812467a2c26412e2",
      "43f856d31baa4726891afa1ac66c7cdf",
      "5ec4d6ff571d4ef5aaff4db01375819a",
      "8561a0b965e147e9a2137281aae7f579",
      "ed54b9942b1f4b7f8497a78dea5177cc",
      "5a4d41644a4e4c11a760f78682abcea7",
      "4a71f221a6024a4d8072ed98cdd2815b",
      "99a9b7a0889e46d7b0a5eb681c1790b8",
      "e3f50e3763b24def8173c3c1e2cca1ce",
      "5b09e35c2c2e443787644938ce05b656",
      "be6387b68eeb4f3d8d85d05cc0abdc31",
      "082b5ea08cab45c9b009d61ab36ec29b",
      "cca683850d2d4c63a6fe6e0d18064b1a",
      "4c24cd74dcea4d6aacd5b3bd001f7025",
      "8581e335673a4c5883c5009d56b5ab32",
      "d4b624d8509e4198b1401d737b2c329f",
      "32f751f1b2654b5488ed97e0c8a7fffd",
      "2ad4ead3130941eb94c719a6765abe17",
      "aa16e4e40ee1428ea1743b89fbc9919f",
      "3c7739680b08476b9ce7650d6d4c4236",
      "08b90607efc343328fe4e566048132ac",
      "8da4e3de2f83431b962b7c3c177094ac",
      "fe984a4d89674bbe81d5b3862a1d4695",
      "d149540cbd764eb5a59ecaf7355dacb7",
      "b003d15235a04fbd96003f3ea894c124",
      "bd79a3e67a474487808bba4b48839eae",
      "8d1ae1d85ed043f19d03e24e37c95b3e",
      "5e7aca0b5d56463e9725e219cea2423a",
      "010a32ba33a84a8a8b5bfa78813d0676",
      "a201527d6c774297ba9f25a712d27bf5",
      "ba49010ff96a4df7b15858fa4c9eef38",
      "3fb96f3f4d1b469b9bba5e2a66b8d490",
      "8b50cd09ae5a43aa978d71c595190a2d",
      "f5cf89ecb72e445abde5c486b83fc5a2",
      "52a9a5fca6674437911f7e5839733e17",
      "5b46cb14221c4aec8c100da2d53774b6",
      "3695e84c938b471ea66559f4f31a7e12",
      "120f9eb5c7134a3b945fd7ccf88e8d05",
      "c6c3f578a1234e3faf67ec56e5cbdc6a",
      "4879715dac48403c8b659315f351563e"
     ]
    },
    "executionInfo": {
     "elapsed": 25000,
     "status": "ok",
     "timestamp": 1747011597110,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "M73VDsh_HRqK",
    "outputId": "5877bbd1-6715-4497-a1a1-d414cacb42cc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5be56778384416684dd4c0b3338bd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26684dfd40e446bbc60be9f6fb9da3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71f867a5fcf42d19ac3584a95ae3805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f97a1b667494a2a9c7d6a84ff9ca835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 300,295 || all params: 109,224,206 || trainable%: 0.2749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a9b7a0889e46d7b0a5eb681c1790b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36542 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa16e4e40ee1428ea1743b89fbc9919f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9136 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a201527d6c774297ba9f25a712d27bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['title'], padding = 'max_length', truncation = True)\n",
    "\n",
    "model_id = \"beomi/kcbert-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1747011600140,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "pllAYmAWHskg",
    "outputId": "1fc90708-3a37-40ab-f09d-d12d7f46e939"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, label = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    acc = accuracy_score(label, preds)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "executionInfo": {
     "elapsed": 1842273,
     "status": "ok",
     "timestamp": 1747013445716,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "hY1AOzWwSLgC",
    "outputId": "2d186f6a-8522-4cfe-c15c-886722946821"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ca2cb01184e9>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4568' max='4568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4568/4568 27:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.600200</td>\n",
       "      <td>0.593230</td>\n",
       "      <td>0.796300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1139' max='1139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1139/1139 03:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시간: 27.0분38.74787163734436초\n",
      "GPU 메모리 사용량: 1.60 GB\n",
      "평가 결과:\n",
      "  - eval_loss: 0.7816\n",
      "  - eval_accuracy: 0.7162\n",
      "  - eval_runtime: 183.1693\n",
      "  - eval_samples_per_second: 49.7190\n",
      "  - eval_steps_per_second: 6.2180\n",
      "  - epoch: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "minutes = total_time // 60\n",
    "seconds = total_time % 60\n",
    "gpu_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)\n",
    "eval_results = trainer.evaluate(test_dataset)\n",
    "print(f\"학습 시간: {minutes}분{seconds}초\")\n",
    "print(f\"GPU 메모리 사용량: {gpu_memory:.2f} GB\")\n",
    "print(\"평가 결과:\")\n",
    "for k, v in eval_results.items():\n",
    "    print(f\"  - {k}: {v:.4f}\" if isinstance(v, float) else f\"  - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747013449691,
     "user": {
      "displayName": "구종빈",
      "userId": "04413789043138554649"
     },
     "user_tz": -540
    },
    "id": "cqJ-jUyATUxF",
    "outputId": "6ccb0f5f-403e-4e24-9678-efad4d4c62f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 모델 저장 용량: 44.38 MB (0.04 GB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_dir_size(path):\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "# 모델 저장 디렉토리 (Trainer의 output_dir과 같아야 함)\n",
    "model_dir = \"./results\"\n",
    "\n",
    "# 바이트 → 메가바이트 또는 기가바이트\n",
    "model_size_bytes = get_dir_size(model_dir)\n",
    "model_size_mb = model_size_bytes / (1024 ** 2)\n",
    "model_size_gb = model_size_bytes / (1024 ** 3)\n",
    "\n",
    "print(f\"💾 모델 저장 용량: {model_size_mb:.2f} MB ({model_size_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfJqq5b5Hbd_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1fzK0UCr3spOhmp6xeY5G",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
